{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is used to load the model information from the file, which currently has the following options:\n",
    "#\n",
    "#- Reading functions (lin,log,etc.)\n",
    "#- Read matrix A \n",
    "#- Reads matrix B\n",
    "#- Variables priority vector reading\n",
    "#- Tradeoff coefficient\n",
    "\n",
    "# The modelname field is the name of the file model that is used to read the initial file and name the different output files\n",
    "# The verbose field is a yes/no field that allows you to view the outputs of the\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def loadmodelfromfile(modelname, verbose):\n",
    "    f = open(modelname+'.txt', 'r')\n",
    "    f.readline()\n",
    "    f.readline()\n",
    "    fx = []\n",
    "    A = []\n",
    "    B = []\n",
    "    p = []\n",
    "    l = '_'\n",
    "    e = None\n",
    "    delta = []\n",
    "    while 1:\n",
    "        l = f.readline().rstrip()\n",
    "        if l != '': \n",
    "            fx.append(l) \n",
    "        else: \n",
    "            break\n",
    "    while 1:\n",
    "        l = f.readline().rstrip()\n",
    "        if l != '':\n",
    "            if l.__contains__(','):\n",
    "                l = l.split(',')\n",
    "                l = [float(x) for x in l]\n",
    "                A.append(l)\n",
    "            else:    \n",
    "                A.append(float(l))\n",
    "        else:\n",
    "            break\n",
    "    while 1:\n",
    "        l = f.readline().rstrip()\n",
    "        if l != '':\n",
    "            if l.__contains__(','):\n",
    "                l = l.split(',')\n",
    "                l = [float(x) for x in l]\n",
    "                B.append(l)\n",
    "            else:    \n",
    "                B.append(float(l))\n",
    "        else:\n",
    "            break\n",
    "    f.readline()\n",
    "    f.readline()\n",
    "\n",
    "    try:\n",
    "        for x in f.readline().rstrip().split(','):\n",
    "            p.append(int(x))\n",
    "    except:\n",
    "        pass\n",
    "    f.readline()\n",
    "    try:\n",
    "        e = float(f.readline().rstrip())\n",
    "    except:\n",
    "        pass\n",
    "    f.readline()\n",
    "    f.readline()\n",
    "    f.readline()\n",
    "    try:\n",
    "        for x in f.readline().rstrip().split(','):\n",
    "            delta.append(float(x))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Model: %s\" % modelname)\n",
    "        print(\"Function list: \")\n",
    "        print(fx) \n",
    "        print(\"A matrice: \")\n",
    "        print(A)\n",
    "        print(\"B matrice: \")\n",
    "        print(B)\n",
    "        print(\"Priority factor array (most important to least important): \")\n",
    "        print(p)\n",
    "        print(\"Trade-off coeficiente \")\n",
    "        print(e)\n",
    "        print(\"Tolerances: \")\n",
    "        print(delta)\n",
    "\n",
    "    return fx, A, B, p, e, delta\n",
    "\n",
    "#Test1\n",
    "#modelname = 'Modelo2'\n",
    "#m_fx = []\n",
    "#m_A = []\n",
    "#m_B = []\n",
    "#m_p = []\n",
    "#m_fx,m_A,m_B,m_p,m_e,m_delta = loadmodelfromfile(modelname, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this cell are the functions to convert the values from the original scale to the value scale and vice-versa at the end to display the results\n",
    "from itertools import count\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "def lin(lin_y,lin_X,lin_Y):\n",
    "    lin_m = (lin_Y[1]-lin_Y[0])/(lin_X[1]-lin_X[0])\n",
    "    lin_b = lin_Y[0] - lin_m*lin_X[0]\n",
    "    lin_x = (lin_y - lin_b)/lin_m\n",
    "    return lin_x\n",
    "             \n",
    "#Functions to convert to value scale\n",
    "def converttovaluescale(el,uf_i,uf_m, A, B):\n",
    "    match uf_m:\n",
    "        case 'lin':\n",
    "            reverse_A = A[uf_i].copy()\n",
    "            reverse_A.sort(reverse=True)\n",
    "            index = A[uf_i].index(min(reverse_A,key=lambda x : x - el > 0 ))\n",
    "            A_uf_i = np.array(A[uf_i])\n",
    "            B_uf_i = np.array(B[uf_i])\n",
    "            if index == len(A[uf_i])-1:\n",
    "                return B_uf_i[index]\n",
    "            else:\n",
    "                return (lin(el,B_uf_i[index:index+2],A_uf_i[index:index+2])) \n",
    "        case 'exp':\n",
    "            return A[uf_i]*math.exp(el)+B[uf_i]\n",
    "        case 'log':\n",
    "            return A[uf_i]*math.log(el)+B[uf_i]\n",
    "        case _:\n",
    "            return -999\n",
    "\n",
    "#Convert to value scale\n",
    "def convertoriginaltovaluescale(modelname, fx, A, B):\n",
    "    df1 = pd.read_csv(modelname+'_originals.csv')\n",
    "    n = len(fx)\n",
    "    for i in range(1,n+1):\n",
    "        df1.iloc[:, i] = df1.iloc[:, i].apply(lambda x: converttovaluescale(x,i-1,fx[i-1],A,B))\n",
    "    df1_headers = ['DMUs']\n",
    "    for i in range(1,n+1):\n",
    "        df1_headers.append('V'+str(i))\n",
    "    df1.columns = df1_headers\n",
    "    df1.to_csv(modelname+\"_R_originals_valuescale.csv\",float_format='%.12f', index=False)\n",
    "    return df1\n",
    "\n",
    "#Functions to convert back to original scale    \n",
    "def converttooriginalscale(el,uf_i,uf_m,A,B):    \n",
    "    if pd.isna(el): return el\n",
    "    match uf_m:\n",
    "        case 'lin':\n",
    "            if B[uf_i][0]>B[uf_i][1]:\n",
    "                A[uf_i].sort(reverse=False)\n",
    "                B[uf_i].sort(reverse=False)\n",
    "            reverse_B = B[uf_i].copy()\n",
    "            reverse_B.sort(reverse=True)            \n",
    "            index = B[uf_i].index(min(reverse_B,key=lambda x : x - el > 0 ))\n",
    "            A_uf_i = np.array(A[uf_i])\n",
    "            B_uf_i = np.array(B[uf_i])\n",
    "            if index == len(B[uf_i])-1:\n",
    "                return A_uf_i[index]\n",
    "            else:\n",
    "                return (lin(el,A_uf_i[index:index+2],B_uf_i[index:index+2]))        \n",
    "        case 'exp':\n",
    "            return math.log((el-B[uf_i])/A[uf_i])\n",
    "        case 'log':\n",
    "            return math.exp((el-B[uf_i])/A[uf_i])\n",
    "        case _:\n",
    "            return -999\n",
    "\n",
    "#Convert back to original scale\n",
    "def convertvaluescaletooriginal(modelname,df_phase2,fx,A,B):\n",
    "    df = pd.read_csv(modelname+'_R_phase2.csv')\n",
    "    n = len(fx)\n",
    "    for i in range(1,n+1):\n",
    "        df.iloc[:, i+1] = df.iloc[:, i+1].apply(lambda x: converttooriginalscale(x,i-1,fx[i-1],A,B))\n",
    "    for i in range(n+1,2*n+1):\n",
    "        df.iloc[:, i+1] = df.iloc[:, i+1].apply(lambda x: converttooriginalscale(x,i-1-(n+1),fx[i-1-(n+1)],A,B))\n",
    "    df.to_csv(modelname+\"_R_final.csv\", float_format='%.12f',index=False)\n",
    "\n",
    "\n",
    "#Test2\n",
    "#df_vscale = convertoriginaltovaluescale(modelname, m_fx , m_A, m_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for robustness analysis\n",
    "def createbounds(modelname,delta):\n",
    "    df1 = pd.read_csv(modelname+'_originals.csv')\n",
    "    df3 = pd.DataFrame()\n",
    "    df3['DMUs'] = df1['DMUs']\n",
    "    for i in range(1,len(df1.columns)):\n",
    "        df3['LB'+str(i)] = df1.iloc[:,i].apply(lambda x: x*(1-delta) if x > 0 else x*(1+delta))\n",
    "        df3['UB'+str(i)] = df1.iloc[:,i].apply(lambda x: x*(1+delta) if x > 0 else x*(1-delta))\n",
    "    df3.to_csv(modelname+\"_R_\"+str(delta)+\"_bounds.csv\",float_format='%.12f', index=False)\n",
    "    return df3    \n",
    "\n",
    "def convertboundsoriginaltovaluescale(modelname, df_robustness_original, fx_delta, A_delta, B_delta, delta):\n",
    "    df1 = pd.read_csv(modelname+'_R_'+str(delta)+'_bounds.csv')\n",
    "    n = len(fx_delta)\n",
    "    for i in range(1,n+1):\n",
    "        df1.iloc[:, i] = df1.iloc[:, i].apply(lambda x: converttovaluescale(x,i-1,fx_delta[i-1],A_delta,B_delta))\n",
    "    for i in range(len(df1)):\n",
    "        for j in range(1,len(df1.columns),2):\n",
    "            if (df1.iloc[i,j]>df1.iloc[i,j+1]):\n",
    "                _aux = df1.iloc[i,j]\n",
    "                df1.iloc[i,j] = df1.iloc[i,j+1]\n",
    "                df1.iloc[i,j+1] = _aux\n",
    "    df1.to_csv(modelname+'_R_'+str(delta)+\"_bounds_valuescale.csv\",float_format='%.12f', index=False)\n",
    "    return df1  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Phase one for robustness analysis\n",
    "#Read several dealtas (0.05,0.10,etc.) and present data in columns (DMU, d_opt(para 5% - esq), d_pess(5% - dir))\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import linprog\n",
    "\n",
    "def phase1_robustness_analysis(modelname,load,df_robustness_vscale,p,e,delta):\n",
    "    #Load values\n",
    "    if load:\n",
    "        df_robustness_vscale = pd.read_csv(modelname+'_R_bounds_valuescale.csv') \n",
    "    df_vscale2 = df_robustness_vscale.iloc[:,1:]\n",
    "    nw = int(len(df_vscale2.columns)/2)\n",
    "    ndmu = len(df_vscale2)\n",
    "    _A = df_vscale2.to_numpy()\n",
    "    _Aesq = np.zeros((ndmu,int(nw)))\n",
    "    _Adir = np.zeros((ndmu,int(nw)))\n",
    "\n",
    "    for i in range(ndmu):\n",
    "        for j in range(0,nw):\n",
    "            _Aesq[i,j] = _A[i,2*j]\n",
    "            _Adir[i,j] = _A[i,2*j+1] \n",
    "\n",
    "    res_fase1_esq = []\n",
    "    for i in range(ndmu):\n",
    "        c0 = np.zeros(nw)\n",
    "        c = np.append(c0,1)\n",
    "\n",
    "        A2 = np.copy(_Aesq)\n",
    "        A_27 = np.copy(_Adir[i])\n",
    "        A2[i] = np.zeros(nw)\n",
    "        A3 = A2 - A_27.T\n",
    "\n",
    "        A_ub = np.c_[A3,-1*np.ones((ndmu,1))]\n",
    "        b_ub = np.zeros(ndmu)\n",
    "\n",
    "        A_eq = []\n",
    "        b_eq = []\n",
    "        A_eq0 = np.ones(nw)\n",
    "        A_eq0 = np.append(A_eq0,0)       \n",
    "        A_eq.append(A_eq0.tolist())\n",
    "        b_eq.append(1)\n",
    "\n",
    "        if p:\n",
    "            for i_p in range(len(p)-1):\n",
    "                A_ub1 = np.zeros(nw+1)\n",
    "                A_ub1[p[i_p]-1] = -1\n",
    "                A_ub1[p[i_p+1]-1] = 1\n",
    "                A_ub2 = []\n",
    "                A_ub2.append(A_ub1.tolist())\n",
    "                A_ub = np.r_[A_ub,np.array(A_ub2)]\n",
    "                b_ub = np.append(b_ub,0)\n",
    "            if e:\n",
    "                A_ub3 = np.zeros(nw+1) \n",
    "                A_ub3[p[len(p)-1]-1] = -1*e   \n",
    "                A_ub3[p[0]-1] = 1\n",
    "                A_ub4 = []\n",
    "                A_ub4.append(A_ub3.tolist())\n",
    "                A_ub = np.r_[A_ub,np.array(A_ub4)]\n",
    "                b_ub = np.append(b_ub,0)\n",
    "        \n",
    "        wn_bounds = []\n",
    "        for j in range(nw):\n",
    "            wn_bounds.append((0,None))\n",
    "        wn_bounds.append((None,None))\n",
    "        res = linprog(c, A_ub=A_ub, b_ub=b_ub,A_eq=A_eq, b_eq=b_eq,bounds=wn_bounds)\n",
    "        res2 = np.zeros(nw+2)\n",
    "        res2[0] = i+1\n",
    "        res2[1:] = res.x\n",
    "        res_fase1_esq.append(res2)\n",
    "    \n",
    "    column_names = []\n",
    "    column_names.append('DMUs')\n",
    "    df2 = pd.DataFrame(data = df_robustness_vscale['DMUs'], columns=column_names)\n",
    "    df2['d_'+str(delta)+'_opt'] = np.array(res_fase1_esq)[:,-1].tolist()\n",
    "\n",
    "    res_fase1_dir = []\n",
    "    for i in range(ndmu):\n",
    "        c0 = np.zeros(nw)\n",
    "        c = np.append(c0,1)\n",
    "\n",
    "        A2 = np.copy(_Adir)\n",
    "        A_27 = np.copy(_Aesq[i])\n",
    "        A2[i] = np.zeros(nw)\n",
    "        A3 = A2 - A_27.T\n",
    "\n",
    "        A_ub = np.c_[A3,-1*np.ones((ndmu,1))]\n",
    "        b_ub = np.zeros(ndmu)\n",
    "\n",
    "        A_eq = []\n",
    "        b_eq = []\n",
    "        A_eq0 = np.ones(nw)\n",
    "        A_eq0 = np.append(A_eq0,0)       \n",
    "        A_eq.append(A_eq0.tolist())\n",
    "        b_eq.append(1)\n",
    "\n",
    "        if p:\n",
    "            for i_p in range(len(p)-1):\n",
    "                A_ub1 = np.zeros(nw+1)\n",
    "                A_ub1[p[i_p]-1] = -1\n",
    "                A_ub1[p[i_p+1]-1] = 1\n",
    "                A_ub2 = []\n",
    "                A_ub2.append(A_ub1.tolist())\n",
    "                A_ub = np.r_[A_ub,np.array(A_ub2)]\n",
    "                b_ub = np.append(b_ub,0)\n",
    "            if e:\n",
    "                A_ub3 = np.zeros(nw+1) \n",
    "                A_ub3[p[len(p)-1]-1] = -1*e   \n",
    "                A_ub3[p[0]-1] = 1\n",
    "                A_ub4 = []\n",
    "                A_ub4.append(A_ub3.tolist())\n",
    "                A_ub = np.r_[A_ub,np.array(A_ub4)]\n",
    "                b_ub = np.append(b_ub,0)\n",
    "        \n",
    "        wn_bounds = []\n",
    "        for j in range(nw):\n",
    "            wn_bounds.append((0,None))\n",
    "        wn_bounds.append((None,None))\n",
    "\n",
    "        res = linprog(c, A_ub=A_ub, b_ub=b_ub,A_eq=A_eq, b_eq=b_eq,bounds=wn_bounds)\n",
    "        res2 = np.zeros(nw+2)\n",
    "        res2[0] = i+1\n",
    "        res2[1:] = res.x\n",
    "        res_fase1_dir.append(res2)\n",
    "    \n",
    "    df2['d_'+str(delta)+'_pes'] = np.array(res_fase1_dir)[:,-1]\n",
    "    df2.to_csv(modelname+\"_R_\"+str(delta)+\"_bounds_phase1.csv\", float_format='%.12f', index = False)\n",
    "\n",
    "    return df2\n",
    "\n",
    "#Run model\n",
    "#modelname = 'Modelo2'\n",
    "#df_phase1 = phase1_robustness_analysis(modelname,False,df_robustness_vscale,m_p,m_e,m_delta[0])\n",
    "#print(df_phase1.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This main program runs robustness\n",
    "import pandas as pd\n",
    "modelname = 'Modelo2'\n",
    "#Load mdodel from file  \n",
    "m_fx = []\n",
    "m_A = []\n",
    "m_B = []\n",
    "m_p = []\n",
    "#loadmodelfromfile(modelname, verbose)\n",
    "m_fx,m_A,m_B,m_p,m_e,m_delta = loadmodelfromfile(modelname, False)\n",
    "\n",
    "for m_delta_i in m_delta:\n",
    "    df_robustness_original = createbounds(modelname, m_delta_i)\n",
    "    m_A_delta = []\n",
    "    m_B_delta = []\n",
    "    m_fx_delta = []\n",
    "    for i in range(len(m_fx)):\n",
    "        m_A_delta.append(m_A[i])\n",
    "        m_A_delta.append(m_A[i])\n",
    "        m_B_delta.append(m_B[i])\n",
    "        m_B_delta.append(m_B[i])\n",
    "        m_fx_delta.append(m_fx[i])\n",
    "        m_fx_delta.append(m_fx[i])\n",
    "      \n",
    "        df_robustness_vscale = convertboundsoriginaltovaluescale(modelname, df_robustness_original, m_fx_delta, m_A_delta, m_B_delta, m_delta_i)\n",
    "        phase1_robustness_analysis(modelname,False,df_robustness_vscale,m_p,m_e,m_delta_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta:  0.011  DMU: HU\n",
      "Delta:  0.011  DMU: IT\n",
      "Delta:  0.012  DMU: DK\n",
      "Delta:  0.013000000000000001  DMU: SK\n",
      "Delta:  0.018000000000000006  DMU: PL\n",
      "Delta:  0.019000000000000006  DMU: IE\n",
      "Delta:  0.02400000000000001  DMU: CZ\n",
      "Delta:  0.03800000000000002  DMU: FR\n",
      "Delta:  0.044000000000000025  DMU: UK\n",
      "Delta:  0.054000000000000034  DMU: DE\n",
      "Delta:  0.05700000000000004  DMU: LV\n",
      "Delta:  0.05700000000000004  DMU: RO\n",
      "Delta:  0.10000000000000007  DMU: AT\n",
      "Delta:  0.10000000000000007  DMU: BE\n",
      "Delta:  0.10000000000000007  DMU: MT\n",
      "Delta:  0.10000000000000007  DMU: SE\n",
      "Delta:  0.10100000000000008  DMU: BG\n",
      "Delta:  0.10400000000000008  DMU: CY\n",
      "Delta:  0.10900000000000008  DMU: GR\n",
      "Delta:  0.1420000000000001  DMU: LU\n"
     ]
    }
   ],
   "source": [
    "#Imprimir a pesquisa binaria para descobrir o delta maximo\n",
    "#Resposta com o delta e os valores das eficienciais\n",
    "#Só em relação as DMUS com valroes de eficiencia que variam entre (negativo e positivo)\n",
    "#delta a variar de 0 a 0.25\n",
    "#apanhar o pessimista\n",
    "#Para cada DMU calcular percorrer os desltas calculando as bounds e ir incrementado até que o pessimista seja negativo\n",
    "\n",
    "def determinardeltasparaDMUSinefecientes(modelname,fx,A,B,p,e):\n",
    "    delta = 0.01\n",
    "    dmus_que_ja_apareceram = []\n",
    "    for delta_i in range(200):\n",
    "        delta += 0.001\n",
    "        df_robustness_original = createbounds(modelname,delta)\n",
    "        m_A_delta = []\n",
    "        m_B_delta = []\n",
    "        m_fx_delta = []\n",
    "        for i in range(len(fx)):\n",
    "            m_A_delta.append(A[i])\n",
    "            m_A_delta.append(A[i])\n",
    "            m_B_delta.append(B[i])\n",
    "            m_B_delta.append(B[i])\n",
    "            m_fx_delta.append(fx[i])\n",
    "            m_fx_delta.append(fx[i])\n",
    "        df_robustness_vscale = convertboundsoriginaltovaluescale(modelname, df_robustness_original, m_fx_delta, m_A_delta, m_B_delta, delta)\n",
    "        df_robustness_vscale_phase1 = phase1_robustness_analysis(modelname,False,df_robustness_vscale,p,e,delta)\n",
    "        #Apos a primeira etapa para 0.05 vai correr um algoritmo simular para todas as DMUS com pess negativo e optimo positivo\n",
    "        for i in range(len(df_robustness_vscale_phase1)):\n",
    "            if df_robustness_vscale_phase1.iloc[i,1] < 0 and df_robustness_vscale_phase1.iloc[i,2] > 0 and df_robustness_vscale_phase1.iloc[i,0] not in dmus_que_ja_apareceram:\n",
    "                #testar varios deltas ate encontrar o delta maximo    \n",
    "                dmus_que_ja_apareceram.append(df_robustness_vscale_phase1.iloc[i,0])\n",
    "                print(\"Delta: \", delta, \" DMU:\", df_robustness_vscale_phase1.iloc[i,0])\n",
    "\n",
    "\n",
    "\n",
    "#This main program runs robustness\n",
    "import pandas as pd\n",
    "modelname = 'Modelo2'\n",
    "#Load mdodel from file  \n",
    "m_fx = []\n",
    "m_A = []\n",
    "m_B = []\n",
    "m_p = []\n",
    "#loadmodelfromfile(modelname, verbose)\n",
    "m_fx,m_A,m_B,m_p,m_e,m_delta = loadmodelfromfile(modelname, False)\n",
    "determinardeltasparaDMUSinefecientes(modelname,m_fx,m_A,m_B,m_p,m_e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4604fddfbe3ec3d9d385c207fa0ddb9a05dfef66380401ad05b04bbd42d45367"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
